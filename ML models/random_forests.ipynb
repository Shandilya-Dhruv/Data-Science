{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import import_ipynb\n",
    "# from decision_trees import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "\n",
    "    def __init__(self, left=None, right=None, threshold=None, feature=None, g_score=None, classif = None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.threshold = threshold\n",
    "        self.feature = feature\n",
    "        self.g_score = g_score\n",
    "        self.classif = classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree:\n",
    "\n",
    "    \"\"\"\n",
    "    Limitation : only designed to handle classification with 0 and 1 as classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,max_depth,min_sample_size):\n",
    "        self.root = None\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_size = min_sample_size\n",
    "\n",
    "    def make_split(self, X, feature, threshold, Y):\n",
    "        \"\"\" \n",
    "        desc : makes two lists from the data\n",
    "\n",
    "        X : (numpy) numpy data to be split\n",
    "        feature : (int) the feature number on which we will split the data\n",
    "        threshold : (int) the threshold for splitting\n",
    "        Y : (numpy) the series storing classification of each datapoint\n",
    "\n",
    "        returns : (tuple of lists) returns two lists having the classifications of split data in list format\n",
    "        \"\"\"\n",
    "        l = []\n",
    "        g = []\n",
    "        for i in range(X.shape[0]):\n",
    "            if X[i][feature]<=threshold:\n",
    "                l.append(Y[i])\n",
    "            else:\n",
    "                g.append(Y[i])\n",
    "        \n",
    "        return (l,g)\n",
    "\n",
    "    def gini(self,l):\n",
    "        \"\"\"\n",
    "        desc: calculates gini score\n",
    "\n",
    "        l : (list) stores the classification of each datapoint\n",
    "\n",
    "        returns : (tuple) return gini score(int) and the most occuring class in l\n",
    "        \"\"\"\n",
    "        gin = 0\n",
    "        p = 0\n",
    "        r = (l.count(0)/len(l),l.count(1)/len(l))\n",
    "\n",
    "        classes = np.unique(l)\n",
    "\n",
    "        for i in classes:\n",
    "            t = l.count(i)\n",
    "            if len(l)==0:\n",
    "                t = 0\n",
    "            else:\n",
    "                t = t/len(l)\n",
    "            gin += t*(1-t)\n",
    "            if t>p : \n",
    "                p = t\n",
    "        \n",
    "        return (-gin,r)\n",
    "\n",
    "    def split_data(self,X,feature,threshold):\n",
    "        \"\"\"\n",
    "        desc : splits the dataframe into two dataframes\n",
    "\n",
    "        X : (numpy) numpy data to be split\n",
    "        feature : (int) the feature number on which we will split the data\n",
    "        threshold : (int) the threshold for splitting\n",
    "        \n",
    "        returns : (tuple) two split dataframes\n",
    "        \"\"\"\n",
    "\n",
    "        l = np.zeros((1,X.shape[1]))\n",
    "        g = np.zeros((1,X.shape[1]))\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "\n",
    "            if X[i][feature] <= threshold:\n",
    "                l = np.vstack([l, X[i]])\n",
    "            else:\n",
    "                g = np.vstack([g, X[i]])\n",
    "\n",
    "        return (l[1:],g[1:])\n",
    "\n",
    "    def best_split(self,X,Y):\n",
    "        \"\"\"\n",
    "        desc : finds the best split for the data\n",
    "\n",
    "        X : (numpy) numpy data for which we need the best split\n",
    "        Y: (numpy) the series storing classification of each datapoint\n",
    "\n",
    "        returns : (tuple) returns the (feature(best split feature),threshold(best split feature),gini_score(data),classification(most occuring class of data)) of the best data\n",
    "            return gin as -inf if no such split exists\n",
    "        \"\"\"\n",
    "\n",
    "        gin = float('-inf')\n",
    "        f = \"\"\n",
    "        thresh = float('-inf')\n",
    "\n",
    "        for i in range(X.shape[1]):\n",
    "            for j in range(X.shape[0]):\n",
    "                l,g = self.make_split(X,i,X[j][i],Y)\n",
    "                if len(l)<self.min_sample_size or len(g)<self.min_sample_size:\n",
    "                    continue\n",
    "                num = (len(l)*self.gini(l)[0] + len(g)*self.gini(g)[0])/(len(l)+len(g))\n",
    "                if num>gin:\n",
    "                    gin = num\n",
    "                    f = i\n",
    "                    thresh = X[j][i]\n",
    "\n",
    "        t = self.gini(list(Y))\n",
    "        if thresh == float('-inf') and f == \"\":\n",
    "            return (f,thresh,t[0],-1)\n",
    "        l,g = self.make_split(X,f,thresh,Y)\n",
    "        t_l = self.gini(l)\n",
    "        t_g = self.gini(g)\n",
    "        return (f,thresh,t[0],(t_l[1],t_g[1]))\n",
    "\n",
    "    def build_tree(self,X,depth,Y):\n",
    "        \"\"\"\n",
    "        desc : builds our decision tree\n",
    "\n",
    "        X : (numpy) current numpy data of node\n",
    "        depth : (int) the current depth of the tree\n",
    "        Y: (numpy) the series storing classification of each datapoint\n",
    "\n",
    "        return : (no return type)\n",
    "        \"\"\"\n",
    "\n",
    "        tup = self.best_split(X,Y)\n",
    "        a = node(threshold=tup[1],feature=tup[0],g_score=tup[2],classif=tup[3])\n",
    "\n",
    "        #if size constraint is violated\n",
    "        if tup[1] == float('-inf') and tup[0] == \"\":\n",
    "            return\n",
    "\n",
    "        if depth == 0:\n",
    "            self.root = a\n",
    "            l,g = self.split_data(X,tup[0],tup[1])\n",
    "            Y_l,Y_g = self.make_split(X,tup[0],tup[1],Y)\n",
    "            self.root.left = self.build_tree(l,depth+1,Y_l)\n",
    "            self.root.right = self.build_tree(g,depth+1,Y_g)\n",
    "            return self.root\n",
    "            \n",
    "        elif depth<=self.max_depth and depth>0:\n",
    "            n = a\n",
    "            l,g = self.split_data(X,tup[0],tup[1])\n",
    "            Y_l,Y_g = self.make_split(X,tup[0],tup[1],Y)\n",
    "            n.left = self.build_tree(l,depth+1,Y_l)\n",
    "            n.right = self.build_tree(g,depth+1,Y_g)\n",
    "            return n\n",
    "\n",
    "    def print_tree(self,n,depth):\n",
    "        if n!=None :\n",
    "            s = '   '*depth\n",
    "            print(s,n.threshold,n.feature,n.classif)\n",
    "            self.print_tree(n.left,depth+1)\n",
    "            self.print_tree(n.right,depth+1)\n",
    "\n",
    "    def predict_row(self,X):\n",
    "        \"\"\"\n",
    "        desc : predicts the output for a single row of features from the dataset\n",
    "\n",
    "        X : (numpy row) row of features\n",
    "\n",
    "        return : (int) the appropriate classification\n",
    "        \"\"\"\n",
    "        r = self.root\n",
    "        l = True\n",
    "\n",
    "        while l:\n",
    "            if X[r.feature]<=r.threshold:\n",
    "                if r.left == None:\n",
    "                    l = True\n",
    "                    break\n",
    "                r = r.left\n",
    "            else:\n",
    "                if r.right == None:\n",
    "                    l = False\n",
    "                    break\n",
    "                r = r.right\n",
    "        \n",
    "        c = (-1,-1)\n",
    "\n",
    "        if l:\n",
    "            c = r.classif[0]\n",
    "        else:\n",
    "            c = r.classif[1]\n",
    "\n",
    "        if c[0]>=c[1]:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        \"\"\"\n",
    "        desc : predicts the output for a the test dataset\n",
    "\n",
    "        X : (numpy) the test dataset\n",
    "\n",
    "        return : (list) the appropriate classifications of each row\n",
    "        \"\"\"\n",
    "        l = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            l.append(self.predict_row(X_test[i]))\n",
    "        return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_tree:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        desc : creates an object which holds the random decision tree and the mapping for the features of random dec. tree to our dataset features\n",
    "\n",
    "        return : (None)\n",
    "        \"\"\"\n",
    "        self.mapping = None\n",
    "        self.tree = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_forest:\n",
    "\n",
    "    def __init__(self, num_trees , min_sample_size , max_depth ):\n",
    "        \"\"\"\n",
    "        desc : creates an object which stores relevant parameters for random forest building\n",
    "\n",
    "        num_trees : (int) number of decision trees our random forest consists of\n",
    "        min_sample_size : (int) minimum number of rows in a node\n",
    "        max_depth : (int) the maximum depth a random tree can attain\n",
    "\n",
    "        return : (None)\n",
    "        \"\"\"\n",
    "        self.num_trees = num_trees\n",
    "        self.min_sample_size = min_sample_size\n",
    "        self.max_depth = max_depth\n",
    "        self.list_trees = None\n",
    "\n",
    "    def build_random_tree(self,X,Y):\n",
    "        \"\"\"\n",
    "        desc : builds one random tree in our random forest\n",
    "        \n",
    "        X : (numpy array) the dataset for which we want to make a random forest\n",
    "        Y : (numpy) the results of dataset for which we want random forest\n",
    "\n",
    "        return : (object of random_tree class) object storing the mapping of features and the decision tree made on bootstrapped data\n",
    "        \"\"\"\n",
    "        o = random_forest(num_trees=self.num_trees,min_sample_size=self.min_sample_size,max_depth=self.max_depth)\n",
    "        n = math.floor(np.sqrt(X.shape[1]))\n",
    "        l = list(range(0,n))\n",
    "        m = {}\n",
    "        for i in l:\n",
    "            m[i] = random.randint(0,X.shape[1]-1)\n",
    "        o.mapping = m\n",
    "        \n",
    "        X_rand = np.zeros((X.shape[0],n))\n",
    "        Y_rand = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            r = random.randint(0,X.shape[0]-1)\n",
    "            for j in range(n):\n",
    "                X_rand[i][j] = X[r][m[j]]\n",
    "                Y_rand.append(Y[r])\n",
    "\n",
    "        dec = decision_tree(max_depth=self.max_depth,min_sample_size=self.min_sample_size)\n",
    "        dec.build_tree(X_rand,0,Y_rand)\n",
    "        o.tree = dec\n",
    "        return o\n",
    "\n",
    "    def build_random_forest(self,X,Y):\n",
    "        \"\"\"\n",
    "        desc : builds random forest in a list format\n",
    "        \n",
    "        X : (numpy array) the dataset for which we want to make a random forest\n",
    "        Y : (numpy) the results of dataset for which we want random forest\n",
    "\n",
    "        return : (list of object of random_tree class) returns a list of objects having the decision tree and the appropriate feature mapping to original dataset\n",
    "        \"\"\"\n",
    "        l = []\n",
    "        for i in range(self.num_trees):\n",
    "            o = self.build_random_tree(X,Y)\n",
    "            l.append(o)\n",
    "        self.list_trees = l\n",
    "\n",
    "    def predict_r(self,X):\n",
    "        \"\"\"\n",
    "        desc : predicts the classification of the test dataset\n",
    "        \n",
    "        X : (numpy) the test dataset value for which we want to predict output\n",
    "\n",
    "        return : (int) returns the classification of the datapoint\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        l = self.list_trees\n",
    "        for i in range(len(l)):\n",
    "            m = l[i].mapping\n",
    "            X_new = np.zeros((1,len(m)))\n",
    "            for j in range(len(m)):\n",
    "                t = m[j]\n",
    "                X_new[0][j] = X[t]\n",
    "            \n",
    "            dec = l[i].tree\n",
    "            d = dec.root\n",
    "            res.append(dec.predict_row(X_new.tolist()[0]))\n",
    "        agg = sum(res)/len(res)\n",
    "        if agg>0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        desc : predicts the classification of the test dataset\n",
    "        \n",
    "        X : (numpy array) the test dataset for which we want to predict output\n",
    "\n",
    "        return : (list of int) returns the classification of each datapoint in our test dataset\n",
    "        \"\"\"\n",
    "\n",
    "        res = []\n",
    "        for i in range(X.shape[0]):\n",
    "            res.append(self.predict_r(X[i]))\n",
    "        return res\n",
    "\n",
    "    def print_forest(self):\n",
    "        l = self.list_trees\n",
    "        for i in range(len(l)):\n",
    "            print(\"Forest building completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting input to the required format\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "relevant_features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "train[relevant_features] = imputer.fit_transform(train[relevant_features])\n",
    "test[relevant_features] = imputer.transform(test[relevant_features])\n",
    "\n",
    "#encoding\n",
    "train['Sex'] = train['Sex'].map({'male':0, 'female':1})\n",
    "test['Sex'] = test['Sex'].map({'male':0, 'female':1})\n",
    "train['Embarked'] = train['Embarked'].map({'S':0,'C':1,'Q':2})\n",
    "test['Embarked'] = test['Embarked'].map({'S':0,'C':1,'Q':2})\n",
    "\n",
    "X = train[relevant_features].to_numpy()\n",
    "X_test = test[relevant_features].to_numpy()\n",
    "Y = train['Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest building completed\n",
      "Forest building completed\n"
     ]
    }
   ],
   "source": [
    "o = random_forest(num_trees = 2,min_sample_size=10,max_depth=5)\n",
    "\n",
    "o.build_random_forest(X,Y)\n",
    "o.print_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         0\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test['Survived'] = o.predict(X_test)\n",
    "submissions = test[['PassengerId', 'Survived']]\n",
    "print(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(submissions['Survived'].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
